# ğŸš€ SageMaker Titanic MLOps

![AWS](https://img.shields.io/badge/AWS-SageMaker-orange?logo=amazon-aws&logoColor=white)
![MLOps](https://img.shields.io/badge/MLOps-Pipeline-blue)
![Status](https://img.shields.io/badge/Status-Phase%204%20Complete-brightgreen)

End-to-end MLOps on **AWS SageMaker** using the Titanic dataset: data â†’ feature store â†’ training â†’ deployment â†’ prediction â†’ monitoring â†’ CI/CD.

---

## ğŸ“Œ Phases

### âœ… Phase 1 â€“ Project Initialization
- Local env + venv  
- Repo structure (`src/`, `data/`)  
- `requirements.txt`, `.gitignore`  
- AWS creds + SageMaker access  

#### Quickstart (Phase 1)
```bash
git clone https://github.com/Meerasachp/sagemaker-titanic-mlops.git
cd sagemaker-titanic-mlops

python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

aws configure   # provide IAM creds
# verify region = us-east-1

mkdir data src

# place Titanic dataset (train.csv, test.csv) in data/
âœ… Phase 2 â€“ Feature Store
Feature Group created (online + offline)

Ingestion from data/train.csv

IAM + S3 permissions fixed

Verified rows in Studio Feature Store

Quickstart (Phase 2)
bash
Copy code
python src/feature_store_setup.py
python src/check_feature_group.py   # confirm ACTIVE + schema + row count
AWS Console â†’ SageMaker â†’ Feature Store â†’ Feature groups â†’ titanic-feature-group-*

âœ… Phase 3 â€“ Training & Deployment (XGBoost)
Training: Built with SageMaker XGBoost (script mode)

Artifacts: Stored in S3 (model.tar.gz)

Deployment: Real-time endpoint on SageMaker

Prediction: Live inference working

Example result:

json
Copy code
{"predictions": [{"score": 0.8977}]}
Quickstart (Phase 3)
bash
Copy code
python src/run_training.py     # train XGBoost
python src/deploy.py           # deploy endpoint
python src/predict.py          # test prediction
python src/delete_endpoint.py  # cleanup


âœ… Phase 4 â€“ Monitoring & CI/CD
Serverless endpoint (cost-efficient, $0 idle)

Batch inference with batch_invoke.py

Optional Model Monitor setup (baseline + drift detection)

CI/CD via GitHub Actions:

Smoke test on push/PR â†’ invokes endpoint

Manual Train job (launch SageMaker training)

Manual Canary Deploy (10% traffic to new model)

Quickstart (Phase 4)
Batch predictions

bash
Copy code
python src/batch_invoke.py --input data/sample_rows.csv --output preds.jsonl
head preds.jsonl
Serverless switch (script)

bash
Copy code
./serverless_recreate.sh \
  --endpoint titanic-xgboost-endpoint-1757260241 \
  --model sagemaker-xgboost-2025-09-07-15-50-46-469 \
  --region us-east-1 --mem 2048 --maxc 5
GitHub Actions (MLOps Pipeline)

smoke-test â†’ auto on push/PR

train â†’ manual run, launches SageMaker training (cicd/train_job.py)

canary-deploy â†’ manual run, 10% traffic shift (cicd/deploy_canary.py)

ğŸ“‚ Structure
plaintext
Copy code
sagemaker-titanic-mlops/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ test.csv
â”‚   â”œâ”€â”€ sample_rows.csv
â”‚   â””â”€â”€ baseline_features.csv
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ feature_store_setup.py
â”‚   â”œâ”€â”€ check_feature_group.py
â”‚   â”œâ”€â”€ run_training.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ deploy.py
â”‚   â”œâ”€â”€ predict.py
â”‚   â”œâ”€â”€ delete_endpoint.py
â”‚   â”œâ”€â”€ invoke_test.py
â”‚   â”œâ”€â”€ batch_invoke.py
â”‚   â””â”€â”€ monitor_setup.py
â”œâ”€â”€ cicd/
â”‚   â”œâ”€â”€ train_job.py
â”‚   â””â”€â”€ deploy_canary.py
â”œâ”€â”€ .github/workflows/mlops.yml
â”œâ”€â”€ serverless_recreate.sh
â””â”€â”€ README.md

ğŸ› ï¸ Tech
AWS SageMaker (Feature Store, Training, Endpoints, Serverless Inference)

XGBoost (1.5+ â†’ 1.7-1)

Python / Pandas / scikit-learn

GitHub Actions (CI/CD)

S3, IAM, CloudWatch

ğŸ‘¤ Author
Meerasa (Max) â€” DevOps / MLOps Engineer
ğŸ”— GitHub
