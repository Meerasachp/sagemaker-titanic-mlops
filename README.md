# ğŸš€ SageMaker Titanic MLOps

![AWS](https://img.shields.io/badge/AWS-SageMaker-orange?logo=amazon-aws&logoColor=white)
![MLOps](https://img.shields.io/badge/MLOps-Pipeline-blue)
![Status](https://img.shields.io/badge/Status-Phase%203%20Complete-brightgreen)

End-to-end MLOps on **AWS SageMaker** using the Titanic dataset: data â†’ feature store â†’ training â†’ deployment â†’ prediction.

---

## ğŸ“Œ Phases

### âœ… Phase 1 â€“ Project Initialization
- Local env + venv  
- Repo structure (`src/`, `data/`)  
- `requirements.txt`, `.gitignore`  
- AWS creds + SageMaker access  


**Quickstart (Phase 1)**  
```bash
# Clone the repo
git clone https://github.com/Meerasachp/sagemaker-titanic-mlops.git
cd sagemaker-titanic-mlops

# Create virtual env
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
bash
Copy code
# Configure AWS
aws configure
# Provide IAM user credentials with SageMaker + S3 access
# Verify default region = us-east-1
bash
Copy code
# Prepare project structure
mkdir data src
# Place Titanic dataset (train.csv, test.csv) in data/


âœ… Phase 2 â€“ Feature Store
Feature Group created (online + offline)

Ingestion from data/train.csv

IAM + S3 permissions fixed

Verified rows in Studio Feature Store

Quickstart (Phase 2)

bash
Copy code
# Create Feature Group
python src/feature_store_setup.py
bash
Copy code
# Check Feature Group status
python src/check_feature_group.py
Confirms FG is ACTIVE

Lists schema + record count

text
Copy code
AWS Console â†’ SageMaker â†’ Feature Store â†’ Feature groups  
Search for titanic-feature-group-* and explore rows (Name, Sex, Age, Ticket, Cabin, etc.)


âœ… Phase 3 â€“ Training & Deployment (XGBoost)
Training: Built with SageMaker XGBoost (script mode)

Artifacts: Stored in S3 (model.tar.gz)

Deployment: Real-time endpoint on SageMaker

Prediction: Live inference working

Example result:

json
Copy code
{"predictions": [{"score": 0.8977}]}
Quickstart (Phase 3)

bash
Copy code
# Train (XGBoost, script mode)
python src/run_training.py
bash
Copy code
# Deploy endpoint
python src/deploy.py
bash
Copy code
# Predict
python src/predict.py
bash
Copy code
# Delete endpoint (stop costs)
python src/delete_endpoint.py


ğŸ”œ Phase 4 â€“ Monitoring & CI/CD
Model Monitor (data/quality/drift)

CI/CD with SageMaker Pipelines & GitHub Actions

Auto retraining triggers
 

ğŸ“‚ Structure
css
Copy code
sagemaker-titanic-mlops/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.csv
â”‚   â””â”€â”€ test.csv
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ feature_store_setup.py
â”‚   â”œâ”€â”€ check_feature_group.py
â”‚   â”œâ”€â”€ run_training.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ deploy.py
â”‚   â”œâ”€â”€ predict.py
â”‚   â””â”€â”€ delete_endpoint.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


ğŸ› ï¸ Tech
AWS SageMaker (Feature Store, Training, Endpoints)

XGBoost (1.5+)

Python / Pandas / scikit-learn

S3, IAM, CloudWatch



ğŸ‘¤ Author
Meerasa (Max) â€” DevOps/MLOps
ğŸ”— GitHub
